{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install monai","metadata":{"execution":{"iopub.status.busy":"2023-10-25T12:25:04.854897Z","iopub.execute_input":"2023-10-25T12:25:04.855330Z","iopub.status.idle":"2023-10-25T12:25:21.885171Z","shell.execute_reply.started":"2023-10-25T12:25:04.855295Z","shell.execute_reply":"2023-10-25T12:25:21.884129Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting monai\n  Downloading monai-1.3.0-202310121228-py3-none-any.whl (1.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from monai) (1.23.5)\nRequirement already satisfied: torch>=1.9 in /opt/conda/lib/python3.10/site-packages (from monai) (2.0.0+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9->monai) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\nInstalling collected packages: monai\nSuccessfully installed monai-1.3.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-10-25T12:25:21.887474Z","iopub.execute_input":"2023-10-25T12:25:21.887889Z","iopub.status.idle":"2023-10-25T12:25:22.985493Z","shell.execute_reply.started":"2023-10-25T12:25:21.887848Z","shell.execute_reply":"2023-10-25T12:25:22.984320Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/bin/bash: nvidia-smi: command not found\n","output_type":"stream"}]},{"cell_type":"code","source":"!conda install pytorch torchvision -c pytorch","metadata":{"execution":{"iopub.status.busy":"2023-10-25T12:25:22.987842Z","iopub.execute_input":"2023-10-25T12:25:22.988248Z","iopub.status.idle":"2023-10-25T12:26:44.084846Z","shell.execute_reply.started":"2023-10-25T12:25:22.988200Z","shell.execute_reply":"2023-10-25T12:26:44.083268Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Retrieving notices: ...working... done\nCollecting package metadata (current_repodata.json): failed\n\n# >>>>>>>>>>>>>>>>>>>>>> ERROR REPORT <<<<<<<<<<<<<<<<<<<<<<\n\n    Traceback (most recent call last):\n      File \"/opt/conda/lib/python3.10/site-packages/conda/gateways/repodata/__init__.py\", line 187, in conda_http_errors\n        yield\n      File \"/opt/conda/lib/python3.10/site-packages/conda/gateways/repodata/__init__.py\", line 153, in repodata\n        response.raise_for_status()\n      File \"/opt/conda/lib/python3.10/site-packages/requests/models.py\", line 1021, in raise_for_status\n        raise HTTPError(http_error_msg, response=self)\n    requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://conda.anaconda.org/rapidsai/linux-64/current_repodata.json\n    \n    During handling of the above exception, another exception occurred:\n    \n    Traceback (most recent call last):\n      File \"/opt/conda/lib/python3.10/site-packages/requests/models.py\", line 971, in json\n        return complexjson.loads(self.text, **kwargs)\n      File \"/opt/conda/lib/python3.10/site-packages/simplejson/__init__.py\", line 514, in loads\n        return _default_decoder.decode(s)\n      File \"/opt/conda/lib/python3.10/site-packages/simplejson/decoder.py\", line 386, in decode\n        obj, end = self.raw_decode(s)\n      File \"/opt/conda/lib/python3.10/site-packages/simplejson/decoder.py\", line 416, in raw_decode\n        return self.scan_once(s, idx=_w(s, idx).end())\n    simplejson.errors.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n    \n    During handling of the above exception, another exception occurred:\n    \n    Traceback (most recent call last):\n      File \"/opt/conda/lib/python3.10/site-packages/conda/exception_handler.py\", line 16, in __call__\n        return func(*args, **kwargs)\n      File \"/opt/conda/lib/python3.10/site-packages/conda/cli/main.py\", line 84, in main_subshell\n        exit_code = do_call(args, p)\n      File \"/opt/conda/lib/python3.10/site-packages/conda/cli/conda_argparse.py\", line 126, in do_call\n        return getattr(module, func_name)(args, parser)\n      File \"/opt/conda/lib/python3.10/site-packages/conda/notices/core.py\", line 118, in wrapper\n        return_value = func(*args, **kwargs)\n      File \"/opt/conda/lib/python3.10/site-packages/conda/cli/main_install.py\", line 22, in execute\n        install(args, parser, \"install\")\n      File \"/opt/conda/lib/python3.10/site-packages/conda/cli/install.py\", line 309, in install\n        unlink_link_transaction = solver.solve_for_transaction(\n      File \"/opt/conda/lib/python3.10/site-packages/conda/core/solve.py\", line 153, in solve_for_transaction\n        unlink_precs, link_precs = self.solve_for_diff(\n      File \"/opt/conda/lib/python3.10/site-packages/conda/core/solve.py\", line 214, in solve_for_diff\n        final_precs = self.solve_final_state(\n      File \"/opt/conda/lib/python3.10/site-packages/conda/core/solve.py\", line 357, in solve_final_state\n        ssc = self._collect_all_metadata(ssc)\n      File \"/opt/conda/lib/python3.10/site-packages/conda/common/io.py\", line 83, in decorated\n        return f(*args, **kwds)\n      File \"/opt/conda/lib/python3.10/site-packages/conda/core/solve.py\", line 571, in _collect_all_metadata\n        index, r = self._prepare(prepared_specs)\n      File \"/opt/conda/lib/python3.10/site-packages/conda/core/solve.py\", line 1285, in _prepare\n        reduced_index = get_reduced_index(\n      File \"/opt/conda/lib/python3.10/site-packages/conda/core/index.py\", line 286, in get_reduced_index\n        new_records = SubdirData.query_all(\n      File \"/opt/conda/lib/python3.10/site-packages/conda/core/subdir_data.py\", line 157, in query_all\n        result = tuple(\n      File \"/opt/conda/lib/python3.10/concurrent/futures/_base.py\", line 621, in result_iterator\n        yield _result_or_cancel(fs.pop())\n      File \"/opt/conda/lib/python3.10/concurrent/futures/_base.py\", line 319, in _result_or_cancel\n        return fut.result(timeout)\n      File \"/opt/conda/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n        return self.__get_result()\n      File \"/opt/conda/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n        raise self._exception\n      File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n        result = self.fn(*self.args, **self.kwargs)\n      File \"/opt/conda/lib/python3.10/site-packages/conda/core/subdir_data.py\", line 142, in subdir_query\n        return tuple(\n      File \"/opt/conda/lib/python3.10/site-packages/conda/core/subdir_data.py\", line 164, in query\n        self.load()\n      File \"/opt/conda/lib/python3.10/site-packages/conda/core/subdir_data.py\", line 264, in load\n        _internal_state = self._load()\n      File \"/opt/conda/lib/python3.10/site-packages/conda/core/subdir_data.py\", line 321, in _load\n        repodata, state = fetcher.fetch_latest_parsed()\n      File \"/opt/conda/lib/python3.10/site-packages/conda/gateways/repodata/__init__.py\", line 757, in fetch_latest_parsed\n        parsed, state = self.fetch_latest()\n      File \"/opt/conda/lib/python3.10/site-packages/conda/gateways/repodata/__init__.py\", line 879, in fetch_latest\n        raw_repodata = repo.repodata(cache.state)  # type: ignore\n      File \"/opt/conda/lib/python3.10/site-packages/conda/gateways/repodata/__init__.py\", line 143, in repodata\n        with conda_http_errors(self._url, filename):\n      File \"/opt/conda/lib/python3.10/contextlib.py\", line 153, in __exit__\n        self.gen.throw(typ, value, traceback)\n      File \"/opt/conda/lib/python3.10/site-packages/conda/gateways/repodata/__init__.py\", line 234, in conda_http_errors\n        raise RepodataIsEmpty(\n      File \"/opt/conda/lib/python3.10/site-packages/conda/exceptions.py\", line 527, in __init__\n        body = response.json()\n      File \"/opt/conda/lib/python3.10/site-packages/requests/models.py\", line 975, in json\n        raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n    requests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\n`$ /opt/conda/bin/conda install pytorch torchvision -c pytorch`\n\n  environment variables:\n                 CIO_TEST=<not set>\n               CONDA_ROOT=/opt/conda\n           CURL_CA_BUNDLE=<not set>\n          LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-\n                          gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64::/opt/conda/lib\n               LD_PRELOAD=<not set>\n             LIBRARY_PATH=:/opt/conda/lib\n                     PATH=/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin\n                          :/bin\n               PYTHONPATH=/kaggle/lib/kagglegym:/kaggle/lib\n           PYTHONUSERBASE=/root/.local\n       REQUESTS_CA_BUNDLE=<not set>\n            SSL_CERT_FILE=<not set>\n           TESSERACT_PATH=/usr/bin/tesseract\n\n     active environment : None\n       user config file : /root/.condarc\n populated config files : /opt/conda/.condarc\n                          /root/.condarc\n          conda version : 23.5.0\n    conda-build version : not installed\n         python version : 3.10.12.final.0\n       virtual packages : __archspec=1=x86_64\n                          __glibc=2.31=0\n                          __linux=5.15.133=0\n                          __unix=0=0\n       base environment : /opt/conda  (writable)\n      conda av data dir : /opt/conda/etc/conda\n  conda av metadata url : None\n           channel URLs : https://conda.anaconda.org/pytorch/linux-64\n                          https://conda.anaconda.org/pytorch/noarch\n                          https://conda.anaconda.org/rapidsai/linux-64\n                          https://conda.anaconda.org/rapidsai/noarch\n                          https://conda.anaconda.org/nvidia/linux-64\n                          https://conda.anaconda.org/nvidia/noarch\n                          https://conda.anaconda.org/conda-forge/linux-64\n                          https://conda.anaconda.org/conda-forge/noarch\n                          https://repo.anaconda.com/pkgs/main/linux-64\n                          https://repo.anaconda.com/pkgs/main/noarch\n                          https://repo.anaconda.com/pkgs/r/linux-64\n                          https://repo.anaconda.com/pkgs/r/noarch\n          package cache : /opt/conda/pkgs\n                          /root/.conda/pkgs\n       envs directories : /opt/conda/envs\n                          /root/.conda/envs\n               platform : linux-64\n             user-agent : conda/23.5.0 requests/2.31.0 CPython/3.10.12 Linux/5.15.133+ ubuntu/20.04.6 glibc/2.31\n                UID:GID : 0:0\n             netrc file : None\n           offline mode : False\n\n\nAn unexpected error has occurred. Conda has prepared the above report.\n\nIf submitted, this report will be used by core maintainers to improve\nfuture releases of conda.\nWould you like conda to send this report to the core maintainers? [y/N]: \nTimeout reached. No report sent.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install monai\nimport numpy\nfrom monai.utils import first\nimport matplotlib.pyplot as plt\nimport torch\nimport os\nimport numpy as np\nfrom monai.losses import DiceLoss\nfrom tqdm import tqdm\n\ndef dice_metric(predicted, target):\n    '''\n    In this function we take `predicted` and `target` (label) to calculate the dice coeficient then we use it \n    to calculate a metric value for the training and the validation.\n    '''\n    dice_value = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n    value = 1 - dice_value(predicted, target).item()\n    return value\n\ndef calculate_weights(val1, val2):\n    '''\n    In this function we take the number of the background and the forgroud pixels to return the `weights` \n    for the cross entropy loss values.\n    '''\n    count = np.array([val1, val2])\n    summ = count.sum()\n    weights = count/summ\n    weights = 1/weights\n    summ = weights.sum()\n    weights = weights/summ\n    return torch.tensor(weights, dtype=torch.float32)\n\ndef train(model, data_in, loss, optim, max_epochs, model_dir, test_interval=1 , device=torch.device(\"cuda:0\")):\n    best_metric = -1\n    best_metric_epoch = -1\n    save_loss_train = []\n    save_loss_test = []\n    save_metric_train = []\n    save_metric_test = []\n    train_loader, test_loader = data_in\n\n    for epoch in range(max_epochs):\n        print(\"-\" * 10)\n        print(f\"epoch {epoch + 1}/{max_epochs}\")\n        model.train()\n        train_epoch_loss = 0\n        train_step = 0\n        epoch_metric_train = 0\n        for batch_data in train_loader:\n            \n            train_step += 1\n\n            volume = batch_data[\"vol\"]\n            label = batch_data[\"seg\"]\n            label = label != 0\n            volume, label = (volume.to(device), label.to(device))\n\n            optim.zero_grad()\n            outputs = model(volume)\n            \n            train_loss = loss(outputs, label)\n            \n            train_loss.backward()\n            optim.step()\n\n            train_epoch_loss += train_loss.item()\n            print(\n                f\"{train_step}/{len(train_loader) // train_loader.batch_size}, \"\n                f\"Train_loss: {train_loss.item():.4f}\")\n\n            train_metric = dice_metric(outputs, label)\n            epoch_metric_train += train_metric\n            print(f'Train_dice: {train_metric:.4f}')\n\n        print('-'*20)\n        \n        train_epoch_loss /= train_step\n        print(f'Epoch_loss: {train_epoch_loss:.4f}')\n        save_loss_train.append(train_epoch_loss)\n        np.save(os.path.join(model_dir, 'loss_train.npy'), save_loss_train)\n        \n        epoch_metric_train /= train_step\n        print(f'Epoch_metric: {epoch_metric_train:.4f}')\n\n        save_metric_train.append(epoch_metric_train)\n        np.save(os.path.join(model_dir, 'metric_train.npy'), save_metric_train)\n\n        if (epoch + 1) % test_interval == 0:\n\n            model.eval()\n            with torch.no_grad():\n                test_epoch_loss = 0\n                test_metric = 0\n                epoch_metric_test = 0\n                test_step = 0\n\n                for test_data in test_loader:\n\n                    test_step += 1\n\n                    test_volume = test_data[\"vol\"]\n                    test_label = test_data[\"seg\"]\n                    test_label = test_label != 0\n                    test_volume, test_label = (test_volume.to(device), test_label.to(device),)\n                    \n                    test_outputs = model(test_volume)\n                    \n                    test_loss = loss(test_outputs, test_label)\n                    test_epoch_loss += test_loss.item()\n                    test_metric = dice_metric(test_outputs, test_label)\n                    epoch_metric_test += test_metric\n                    \n                \n                test_epoch_loss /= test_step\n                print(f'test_loss_epoch: {test_epoch_loss:.4f}')\n                save_loss_test.append(test_epoch_loss)\n                np.save(os.path.join(model_dir, 'loss_test.npy'), save_loss_test)\n\n                epoch_metric_test /= test_step\n                print(f'test_dice_epoch: {epoch_metric_test:.4f}')\n                save_metric_test.append(epoch_metric_test)\n                np.save(os.path.join(model_dir, 'metric_test.npy'), save_metric_test)\n\n                if epoch_metric_test > best_metric:\n                    best_metric = epoch_metric_test\n                    best_metric_epoch = epoch + 1\n                    torch.save(model.state_dict(), os.path.join(\n                        model_dir, \"best_metric_model.pth\"))\n                \n                print(\n                    f\"current epoch: {epoch + 1} current mean dice: {test_metric:.4f}\"\n                    f\"\\nbest mean dice: {best_metric:.4f} \"\n                    f\"at epoch: {best_metric_epoch}\"\n                )\n\n\n    print(\n        f\"train completed, best_metric: {best_metric:.4f} \"\n        f\"at epoch: {best_metric_epoch}\")\n\n\ndef show_patient(data, SLICE_NUMBER=1, train=True, test=False):\n    \"\"\"\n    This function is to show one patient from your datasets, so that you can si if the it is okay or you need \n    to change/delete something.\n\n    `data`: this parameter should take the patients from the data loader, which means you need to can the function\n    prepare first and apply the transforms that you want after that pass it to this function so that you visualize \n    the patient with the transforms that you want.\n    `SLICE_NUMBER`: this parameter will take the slice number that you want to display/show\n    `train`: this parameter is to say that you want to display a patient from the training data (by default it is true)\n    `test`: this parameter is to say that you want to display a patient from the testing patients.\n    \"\"\"\n\n    check_patient_train, check_patient_test = data\n\n    view_train_patient = first(check_patient_train)\n    view_test_patient = first(check_patient_test)\n\n    \n    if train:\n        plt.figure(\"Visualization Train\", (12, 6))\n        plt.subplot(1, 2, 1)\n        plt.title(f\"vol {SLICE_NUMBER}\")\n        plt.imshow(view_train_patient[\"vol\"][0, 0, :, :, SLICE_NUMBER], cmap=\"gray\")\n\n        plt.subplot(1, 2, 2)\n        plt.title(f\"seg {SLICE_NUMBER}\")\n        plt.imshow(view_train_patient[\"seg\"][0, 0, :, :, SLICE_NUMBER])\n        plt.show()\n    \n    if test:\n        plt.figure(\"Visualization Test\", (12, 6))\n        plt.subplot(1, 2, 1)\n        plt.title(f\"vol {SLICE_NUMBER}\")\n        plt.imshow(view_test_patient[\"vol\"][0, 0, :, :, SLICE_NUMBER], cmap=\"gray\")\n\n        plt.subplot(1, 2, 2)\n        plt.title(f\"seg {SLICE_NUMBER}\")\n        plt.imshow(view_test_patient[\"seg\"][0, 0, :, :, SLICE_NUMBER])\n        plt.show()\n\n\ndef calculate_pixels(data):\n    val = np.zeros((1, 2))\n\n    for batch in tqdm(data):\n        batch_label = batch[\"seg\"] != 0\n        _, count = np.unique(batch_label, return_counts=True)\n\n        if len(count) == 1:\n            count = np.append(count, 0)\n        val += count\n\n    print('The last values:', val)\n    return val","metadata":{"execution":{"iopub.status.busy":"2023-10-25T12:26:44.087565Z","iopub.execute_input":"2023-10-25T12:26:44.087991Z","iopub.status.idle":"2023-10-25T12:27:15.516880Z","shell.execute_reply.started":"2023-10-25T12:26:44.087953Z","shell.execute_reply":"2023-10-25T12:27:15.515513Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: monai in /opt/conda/lib/python3.10/site-packages (1.3.0)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from monai) (1.23.5)\nRequirement already satisfied: torch>=1.9 in /opt/conda/lib/python3.10/site-packages (from monai) (2.0.0+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9->monai) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q git+https://github.com/ChenjieXu/dicom2nifti@patch-1 pydicom","metadata":{"execution":{"iopub.status.busy":"2023-10-25T12:27:15.520519Z","iopub.execute_input":"2023-10-25T12:27:15.520954Z","iopub.status.idle":"2023-10-25T12:27:43.222031Z","shell.execute_reply.started":"2023-10-25T12:27:15.520916Z","shell.execute_reply":"2023-10-25T12:27:43.220294Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import os\nfrom glob import glob\nimport shutil\nfrom tqdm import tqdm\nimport dicom2nifti\nimport numpy as np\nimport nibabel as nib\nfrom monai.transforms import(\n    Compose,\n    AddChanneld,\n    LoadImaged,\n    Resized,\n    ToTensord,\n    Spacingd,\n    Orientationd,\n    ScaleIntensityRanged,\n    CropForegroundd,\n)\nfrom monai.data import DataLoader, Dataset, CacheDataset\nfrom monai.utils import set_determinism\n\n\"\"\"\nThis file is for preporcessing only, it contains all the functions that you need\nto make your data ready for training.\n\nYou need to install the required libraries if you do not already have them.\n\npip install os, ...\n\"\"\"\n\ndef create_groups(in_dir, out_dir, Number_slices):\n    '''\n    This function is to get the last part of the path so that we can use it to name the folder.\n    `in_dir`: the path to your folders that contain dicom files\n    `out_dir`: the path where you want to put the converted nifti files\n    `Number_slices`: here you put the number of slices that you need for your project and it will \n    create groups with this number.\n    '''\n\n    for patient in glob(in_dir + '/*'):\n        patient_name = os.path.basename(os.path.normpath(patient))\n\n        # Here we need to calculate the number of folders which mean into how many groups we will divide the number of slices\n        number_folders = int(len(glob(patient + '/*')) / Number_slices)\n\n        for i in range(number_folders):\n            output_path = os.path.join(out_dir, patient_name + '_' + str(i))\n            os.mkdir(output_path)\n\n            # Move the slices into a specific folder so that you will save memory in your desk\n            for i, file in enumerate(glob(patient + '/*')):\n                if i == Number_slices + 1:\n                    break\n                \n                shutil.move(file, output_path)\n\n\ndef dcm2nifti(in_dir, out_dir):\n    '''\n    This function will be used to convert dicoms into nifti files after creating the groups with \n    the number of slices that you want.\n    `in_dir`: the path to the folder where you have all the patients (folder of all the groups).\n    `out_dir`: the path to the output, which means where you want to save the converted nifties.\n    '''\n\n    for folder in tqdm(glob(in_dir + '/*')):\n        patient_name = os.path.basename(os.path.normpath(folder))\n        dicom2nifti.dicom_series_to_nifti(folder, os.path.join(out_dir, patient_name + '.nii.gz'))\n\n\ndef find_empy(in_dir):\n    '''\n    This function will help you to find the empty volumes that you may not need for your training\n    so instead of opening all the files and search for the empty ones, them use this function to make it quick.\n    '''\n    \n    list_patients = []\n    for patient in glob(os.path.join(in_dir, '*')):\n        img = nib.load(patient)\n\n        if len(np.unique(img.get_fdata())) > 2:\n            print(os.path.basename(os.path.normpath(patient)))\n            list_patients.append(os.path.basename(os.path.normpath(patient)))\n    \n    return list_patients\n\n\ndef prepare(in_dir, pixdim=(1.5, 1.5, 1.0), a_min=-200, a_max=200, spatial_size=[128,128,64], cache=False):\n\n    \"\"\"\n    This function is for preprocessing, it contains only the basic transforms, but you can add more operations that you \n    find in the Monai documentation.\n    https://monai.io/docs.html\n    \"\"\"\n\n    set_determinism(seed=0)\n\n    path_train_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))\n    path_train_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))\n\n    path_test_volumes = sorted(glob(os.path.join(in_dir, \"TestVolumes\", \"*.nii.gz\")))\n    path_test_segmentation = sorted(glob(os.path.join(in_dir, \"TestSegmentation\", \"*.nii.gz\")))\n\n    train_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_train_volumes, path_train_segmentation)]\n    test_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_test_volumes, path_test_segmentation)]\n\n    train_transforms = Compose(\n        [\n            LoadImaged(keys=[\"vol\", \"seg\"]),\n            AddChanneld(keys=[\"vol\", \"seg\"]),\n            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True), \n            CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\"),\n            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),   \n            ToTensord(keys=[\"vol\", \"seg\"]),\n\n        ]\n    )\n\n    test_transforms = Compose(\n        [\n            LoadImaged(keys=[\"vol\", \"seg\"]),\n            AddChanneld(keys=[\"vol\", \"seg\"]),\n            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max,b_min=0.0, b_max=1.0, clip=True), \n            CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),   \n            ToTensord(keys=[\"vol\", \"seg\"]),\n\n            \n        ]\n    )\n\n    if cache:\n        train_ds = CacheDataset(data=train_files, transform=train_transforms,cache_rate=1.0)\n        train_loader = DataLoader(train_ds, batch_size=1)\n\n        test_ds = CacheDataset(data=test_files, transform=test_transforms, cache_rate=1.0)\n        test_loader = DataLoader(test_ds, batch_size=1)\n\n        return train_loader, test_loader\n\n    else:\n        train_ds = Dataset(data=train_files, transform=train_transforms)\n        train_loader = DataLoader(train_ds, batch_size=1)\n\n        test_ds = Dataset(data=test_files, transform=test_transforms)\n        test_loader = DataLoader(test_ds, batch_size=1)\n\n        return train_loader, test_loader\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-25T12:27:43.224208Z","iopub.execute_input":"2023-10-25T12:27:43.224677Z","iopub.status.idle":"2023-10-25T12:27:44.500999Z","shell.execute_reply.started":"2023-10-25T12:27:43.224633Z","shell.execute_reply":"2023-10-25T12:27:44.498578Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/IPython/core/\u001b[0m\u001b[1;33minteractiveshell.py\u001b[0m:\u001b[94m3508\u001b[0m in \u001b[92mrun_code\u001b[0m        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3505 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m async_:                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3506 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mawait\u001b[0m \u001b[96meval\u001b[0m(code_obj, \u001b[96mself\u001b[0m.user_global_ns, \u001b[96mself\u001b[0m.user_ns)               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3507 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3508 \u001b[2m│   │   │   │   │   \u001b[0mexec(code_obj, \u001b[96mself\u001b[0m.user_global_ns, \u001b[96mself\u001b[0m.user_ns)                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3509 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3510 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Reset our crash handler in place\u001b[0m                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3511 \u001b[0m\u001b[2m│   │   │   │   \u001b[0msys.excepthook = old_excepthook                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m8\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m  5 \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mdicom2nifti\u001b[0m                                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m  6 \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mnumpy\u001b[0m \u001b[94mas\u001b[0m \u001b[4;96mnp\u001b[0m                                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m  7 \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mnibabel\u001b[0m \u001b[94mas\u001b[0m \u001b[4;96mnib\u001b[0m                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m  8 \u001b[94mfrom\u001b[0m \u001b[4;96mmonai\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mtransforms\u001b[0m \u001b[94mimport\u001b[0m(                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m  9 \u001b[0m\u001b[2m│   \u001b[0mCompose,                                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 10 \u001b[0m\u001b[2m│   \u001b[0mAddChanneld,                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 11 \u001b[0m\u001b[2m│   \u001b[0mLoadImaged,                                                                            \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mImportError: \u001b[0mcannot import name \u001b[32m'AddChanneld'\u001b[0m from \u001b[32m'monai.transforms'\u001b[0m \n\u001b[1m(\u001b[0m\u001b[35m/opt/conda/lib/python3.10/site-packages/monai/transforms/\u001b[0m\u001b[95m__init__.py\u001b[0m\u001b[1m)\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/IPython/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">interactiveshell.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3508</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run_code</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3505 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> async_:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3506 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">await</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">eval</span>(code_obj, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_global_ns, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_ns)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3507 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3508 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>exec(code_obj, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_global_ns, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_ns)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3509 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">finally</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3510 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Reset our crash handler in place</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3511 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>sys.excepthook = old_excepthook                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  5 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">dicom2nifti</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  6 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">numpy</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">np</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  7 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">nibabel</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">nib</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>  8 <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">monai.transforms</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span>(                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>Compose,                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>AddChanneld,                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 11 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>LoadImaged,                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ImportError: </span>cannot import name <span style=\"color: #008000; text-decoration-color: #008000\">'AddChanneld'</span> from <span style=\"color: #008000; text-decoration-color: #008000\">'monai.transforms'</span> \n<span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080\">/opt/conda/lib/python3.10/site-packages/monai/transforms/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">__init__.py</span><span style=\"font-weight: bold\">)</span>\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"from monai.utils import first, set_determinism\nfrom monai.transforms import(\n    Compose,\n    AddChanneld,\n    LoadImaged,\n    Resized,\n    ToTensord,\n    Spacingd,\n    Orientationd,\n    ScaleIntensityRanged,\n    CropForegroundd,\n    Activations,\n)\n\nfrom monai.networks.nets import UNet\nfrom monai.networks.layers import Norm\nfrom monai.data import CacheDataset, DataLoader, Dataset\n\nimport torch\nimport matplotlib.pyplot as plt\n\nimport os\nfrom glob import glob\nimport numpy as np\n\nfrom monai.inferers import sliding_window_inference","metadata":{"execution":{"iopub.status.busy":"2023-10-25T12:27:44.502623Z","iopub.status.idle":"2023-10-25T12:27:44.503521Z","shell.execute_reply.started":"2023-10-25T12:27:44.503201Z","shell.execute_reply":"2023-10-25T12:27:44.503234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"in_dir = 'D:/Youtube/Organ and Tumor Segmentation/datasets/Task03_Liver/Data_Train_Test'\nmodel_dir = 'D:/Youtube/Organ and Tumor Segmentation/results/results'","metadata":{"execution":{"iopub.status.busy":"2023-10-25T12:27:44.505475Z","iopub.status.idle":"2023-10-25T12:27:44.506130Z","shell.execute_reply.started":"2023-10-25T12:27:44.505824Z","shell.execute_reply":"2023-10-25T12:27:44.505854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\nroot_dir = tempfile.mkdtemp() if directory is None else directory\nprint(root_dir)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T12:27:44.507881Z","iopub.status.idle":"2023-10-25T12:27:44.508918Z","shell.execute_reply.started":"2023-10-25T12:27:44.508654Z","shell.execute_reply":"2023-10-25T12:27:44.508679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task09_Spleen.tar\"\nmd5 = \"410d4a301da4e5b2f6f86ec3ddba524e\"\n\ncompressed_file = os.path.join(root_dir, \"Task09_Spleen.tar\")\ndata_dir = os.path.join(root_dir, \"Task09_Spleen\")\nif not os.path.exists(data_dir):\n    download_and_extract(resource, compressed_file, root_dir, md5)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T12:27:44.510465Z","iopub.status.idle":"2023-10-25T12:27:44.511031Z","shell.execute_reply.started":"2023-10-25T12:27:44.510767Z","shell.execute_reply":"2023-10-25T12:27:44.510791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss = np.load(os.path.join(model_dir, 'loss_train.npy'))\ntrain_metric = np.load(os.path.join(model_dir, 'metric_train.npy'))\ntest_loss = np.load(os.path.join(model_dir, 'loss_test.npy'))\ntest_metric = np.load(os.path.join(model_dir, 'metric_test.npy'))","metadata":{"execution":{"iopub.status.busy":"2023-10-25T12:27:44.512727Z","iopub.status.idle":"2023-10-25T12:27:44.513390Z","shell.execute_reply.started":"2023-10-25T12:27:44.513067Z","shell.execute_reply":"2023-10-25T12:27:44.513098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(\"Results 25 june\", (12, 6))\nplt.subplot(2, 2, 1)\nplt.title(\"Train dice loss\")\nx = [i + 1 for i in range(len(train_loss))]\ny = train_loss\nplt.xlabel(\"epoch\")\nplt.plot(x, y)\n\nplt.subplot(2, 2, 2)\nplt.title(\"Train metric DICE\")\nx = [i + 1 for i in range(len(train_metric))]\ny = train_metric\nplt.xlabel(\"epoch\")\nplt.plot(x, y)\n\nplt.subplot(2, 2, 3)\nplt.title(\"Test dice loss\")\nx = [i + 1 for i in range(len(test_loss))]\ny = test_loss\nplt.xlabel(\"epoch\")\nplt.plot(x, y)\n\nplt.subplot(2, 2, 4)\nplt.title(\"Test metric DICE\")\nx = [i + 1 for i in range(len(test_metric))]\ny = test_metric\nplt.xlabel(\"epoch\")\nplt.plot(x, y)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T12:27:44.515994Z","iopub.status.idle":"2023-10-25T12:27:44.517091Z","shell.execute_reply.started":"2023-10-25T12:27:44.516727Z","shell.execute_reply":"2023-10-25T12:27:44.516759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_train_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))\npath_train_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))\n\npath_test_volumes = sorted(glob(os.path.join(in_dir, \"TestVolumes\", \"*.nii.gz\")))\npath_test_segmentation = sorted(glob(os.path.join(in_dir, \"TestSegmentation\", \"*.nii.gz\")))\n\ntrain_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_train_volumes, path_train_segmentation)]\ntest_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_test_volumes, path_test_segmentation)]\ntest_files = test_files[0:9]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T12:27:44.518954Z","iopub.status.idle":"2023-10-25T12:27:44.519790Z","shell.execute_reply.started":"2023-10-25T12:27:44.519468Z","shell.execute_reply":"2023-10-25T12:27:44.519501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_transforms = Compose(\n    [\n        LoadImaged(keys=[\"vol\", \"seg\"]),\n        AddChanneld(keys=[\"vol\", \"seg\"]),\n        Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n        Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n        ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True), \n        CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n        Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),   \n        ToTensord(keys=[\"vol\", \"seg\"]),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T12:27:44.522080Z","iopub.status.idle":"2023-10-25T12:27:44.522930Z","shell.execute_reply.started":"2023-10-25T12:27:44.522592Z","shell.execute_reply":"2023-10-25T12:27:44.522625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = Dataset(data=test_files, transform=test_transforms)\ntest_loader = DataLoader(test_ds, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T12:27:44.524791Z","iopub.status.idle":"2023-10-25T12:27:44.525942Z","shell.execute_reply.started":"2023-10-25T12:27:44.525586Z","shell.execute_reply":"2023-10-25T12:27:44.525612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\")\nmodel = UNet(\n    dimensions=3,\n    in_channels=1,\n    out_channels=2,\n    channels=(16, 32, 64, 128, 256), \n    strides=(2, 2, 2, 2),\n    num_res_units=2,\n    norm=Norm.BATCH,\n).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T12:27:44.527283Z","iopub.status.idle":"2023-10-25T12:27:44.527684Z","shell.execute_reply.started":"2023-10-25T12:27:44.527492Z","shell.execute_reply":"2023-10-25T12:27:44.527511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\n    os.path.join(model_dir, \"best_metric_model.pth\")))\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T12:27:44.529042Z","iopub.status.idle":"2023-10-25T12:27:44.529455Z","shell.execute_reply.started":"2023-10-25T12:27:44.529254Z","shell.execute_reply":"2023-10-25T12:27:44.529274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sw_batch_size = 4\nroi_size = (128, 128, 64)\nwith torch.no_grad():\n    test_patient = first(test_loader)\n    t_volume = test_patient['vol']\n    #t_segmentation = test_patient['seg']\n    \n    test_outputs = sliding_window_inference(t_volume.to(device), roi_size, sw_batch_size, model)\n    sigmoid_activation = Activations(sigmoid=True)\n    test_outputs = sigmoid_activation(test_outputs)\n    test_outputs = test_outputs > 0.53\n        \n    for i in range(32):\n        # plot the slice [:, :, 80]\n        plt.figure(\"check\", (18, 6))\n        plt.subplot(1, 3, 1)\n        plt.title(f\"image {i}\")\n        plt.imshow(test_patient[\"vol\"][0, 0, :, :, i], cmap=\"gray\")\n        plt.subplot(1, 3, 2)\n        plt.title(f\"label {i}\")\n        plt.imshow(test_patient[\"seg\"][0, 0, :, :, i] != 0)\n        plt.subplot(1, 3, 3)\n        plt.title(f\"output {i}\")\n        plt.imshow(test_outputs.detach().cpu()[0, 1, :, :, i])\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T12:27:44.530726Z","iopub.status.idle":"2023-10-25T12:27:44.531170Z","shell.execute_reply.started":"2023-10-25T12:27:44.530971Z","shell.execute_reply":"2023-10-25T12:27:44.530990Z"},"trusted":true},"execution_count":null,"outputs":[]}]}